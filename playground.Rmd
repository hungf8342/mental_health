---
title: "Playground"
author: "Frances Hung"
date: "10/21/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE)
```
## Motivation

According to the CDC, suicide was the 10th leading cause of death in the US in 2015, and the 2nd leading cause of death among adolescents and young adults. Psychological disorders, particularly depression, are a significant risk factor for suicide especially when they go untreated. There is no reliable way to predict who is at risk for committing suicide, because most screening approaches depend on self-report information and people contemplating on suicide would often deny it when asked. However, even if someone wouldn't tell the truth on a questionnaire, they will often tell Google. Using suicide rate and mental health treatment facilities data as well as Google search term data, our project aims to map the demand for and supply of mental health treatment in California cities.

- use result/visualization as hook

## Variable choice (to be moved to preceding corresponding R chunks)

We originally intended to look at suicide rate and Google Trends data from one year, eg. 2015, but the logit model returned no significant variables as both suicide rate and depression search fluctuate a lot each year, influenced by factors like celebrity death which are not directly relevant to population mental health. Hence, we decided to aggregate suicide rate and Google Trends data over 16 years (constrained by suicide rate data availability), from 1999 to 2015. Since demographic information is fairly stable over time, we used demographic information from the most recent year to train our model.

## Playground


```{r}
require(gtrendsR)
require(ggplot2)
require(dplyr)
require(zipcode)
data("zipcode")
require(ggmap)
```

## Making Dataframes

This gives us a master dataframe of search frequencies of “depression” over the past 12 months in the US which relate for sure to mental health. We can take different dataframes using "$": see the dataframe for details.

longitude and latitude of cities
```{r}
cities_longlat<-read.csv("cal_cities.csv",header=TRUE) %>% select(c(location,Latitude,Longitude))

# updated gtrends data
# I used the one with top 50, instead of the one including cities with low search volume . Though I actually think it is better to use the latter so as to increase our sample size + the effects of low search volume is more smoothed out since we are taking gtrends data over 12 years. 

gtrends <- read.csv("gtrends_20042015_top50.csv")  %>%inner_join(cities_longlat,by="location")

## gtrends only has 49 cities. Stanford (gtrends hit = 99) got lost
```


```{r}
# full gtrends data for all cities
gtrends_full <- read.csv("gtrends_20042015_full.csv") %>%
  inner_join(cities_longlat, by="location")
```

This plots cities_dep.

```{r}
ggplot(cities_dep,aes(x=reorder(location,hits),y=hits))+geom_bar(stat="identity")+theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}

# for (i in 1:length(cities_dep$location)) {
#   place=geocode(cities_dep$location[i],output="latlon",source="dsk")
#   cities_dep$lat[i]=as.numeric(place[1])
#   cities_dep$lon[i]=as.numeric(place[2])
#   print(place)
# }
cities_dep$keyword<-NULL
cities_dep$geo<-NULL
cities_dep$gprop<-NULL
```

prepping facilities data to find number per city
```{r}
facilities<-read.csv("filtered_licensed-healthcare-facility-listing-june-30-2017.csv",header = TRUE)
colnames(facilities)[7]<-"zip"
facilities$zip<-as.character(facilities$zip)
filtered_facs<-inner_join(zipcode,facilities,by="zip")
city_facs<-filtered_facs %>% group_by(city) %>% summarise(facility_cnt=n())
colnames(city_facs)[1]<-"location"
```

prepping suicide data to find number per city, 2004-2015
```{r}
suis<-read.csv(file="death.csv",header=TRUE) %>% filter(Causes.of.Death=="SUI") %>% filter(Year >= 2004)
colnames(suis)[2]<-"zip"
suis$zip<-as.character(suis$zip)
suis2 <-inner_join(zipcode,suis,by="zip") 
# aggregate suicide data across all the years for each city
city_suis<-suis2 %>% group_by(city) %>% summarise(suicides=sum(Count))
colnames(city_suis)[1]<-"location"

# wrangled the data for the purpose of GIS. Need to join to population by zipcode data (same source as population by city data) 
# p/s also need to ensure that the other dem data (esp. those we are going to plot) exist at the zipcode level 
zip_suis <- suis2 %>% group_by(zip) %>% summarise(suicides=sum(Count)) 
gis_suis <-suis2 %>% filter(Year == 2015) %>% select(1:3) %>% left_join(zip_suis,by="zip")


```

Adding in city demographic data for 2017
```{r}

citydem<-read.csv("citydems.csv",header=TRUE)
citydem2<-read.csv("citydems2.csv",header=TRUE)
citydem2$Name<-gsub(",.*","",citydem2$Name)
citydem$Name<-gsub(",.*","",citydem$Name)
citydem$FIPS<-NULL
citydem2$FIPS<-NULL
colnames(citydem)<-c("location", "male", "female","healthcare","bluecollar","whitecollar","nonfamily","medAge","AmInd", "whiteNonHisp","hisp","white","black","asian","medIncome","lessHS","HS","Bachelors","pop","unmarriedMpop","unemployed")
citydem<-inner_join(citydem,city_facs,by="location")
citydem$facility_cnt<-citydem$facility_cnt*100000/citydem$pop
colnames(citydem2)<-c("location","healthcarepp","activities","socialRec","entertainment","pov","presdrugs","healthcarebiz")

# I joined it with the new gtrends data. Not sure why two cities disappeared (meaning the citydem data is not exhaustive altho it should be...). I arranged it by "suicides", and I think our two cities can be Santa Cruz (high suicide/pop) and Santa Clarita (low suicide/pop). I chose these two cities because they have at least 4 zipcodes. Open to revision. 

## citydem data doesn't have Ventura (gtrends hit=93)
```

```{r}
# explanatory data table using full gtrends data (over 180 cities)
logtable_full<-inner_join(citydem,gtrends_full,by="location") %>% inner_join(city_suis,by="location") %>% inner_join(citydem2,by="location") %>% mutate(suicides=suicides*100000/pop,healthcarepp=healthcarepp/pop,activities=activities/pop,socialRec=socialRec/pop,entertainment=entertainment/pop,presdrugs=presdrugs/pop,healthcarebiz=healthcarebiz*1000/pop)
# viewing the data frame reveals that Burbank and Mountain View are repeated 4 times somehow. remove them.
logtable_full <- logtable_full [-c(11,12, 54, 55, 13,154,155), ]
# now the table has 186 cities, whereas the full list of gtrends had 188. not a big loss
logtable_full_crop <- logtable_full [,-c(1,24,25)]
```

```{r}
# normalize the explanatory variables data frame
logtable_full_crop_normalized <- scale(logtable_full_crop) %>% data.frame()
```


```{r}
# try the model again using full gtrends data
set.seed(47)
model_full<-lm((suicides)~.,data=logtable_full_crop_normalized)
summary(model_full)
```
Significant variables include:
Facility density (#mental health facilities/100,000 people) (+), poverty rate (+), % population black (big -), % population native (+), % population asian(big -), median age (+), % population with up to HS education (-), unemployment rate (-), healthcare spending per person (big -), social/recreation/gym club spending (big -), and prescription drug spending (big +). Other variables to consider would be entertainment (excluding movies and museums) spending (big +), % population not in a family household (-), and % population hispanic (big -).



```{r}
#ggplot(logtable_crop,aes(x=whitecollar,y=log(suicides)))+geom_point()
```

```{r}
clustering_table<-logtable_full_crop_normalized %>% select(presdrugs,socialRec,healthcarepp,facility_cnt,asian,AmInd)
rownames(clustering_table)<-logtable_full[,1]
dist_whole<-dist(clustering_table)
cluster_whole<-hclust(dist_whole,method="centroid")
plot(cluster_whole, labels=logtable_full[,1])
groups=cutree(cluster_whole,k=20)
groups
x<-cbind(clustering_table, groups)

suis_cluster<-function(clus) {
  sd<-logtable_full %>% filter(location %in% (rownames(subset(x,groups==clus)))) %>% .[["suicides"]] %>% log() %>% sd()
  mean<-logtable_full %>% filter(location %in% (rownames(subset(x,groups==clus)))) %>% .[["suicides"]] %>% log() %>% mean()
  View(logtable_full%>% filter(location %in% (rownames(subset(x,groups==clus)))))
  return(c(mean,sd))
}
 suis_cluster(5)
#(lapply(1:12,suis_cluster))

```

```{r}
set.seed(10)
kcluster<-kmeans(clustering_table,20, nstart=20)$cluster
kcluster
y<-cbind(clustering_table,kcluster)
logtable_full %>% filter(location %in% (rownames(subset(y,groups==17))))
```

