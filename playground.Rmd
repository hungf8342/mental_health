---
title: "Playground"
author: "Frances Hung"
date: "10/21/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE, tidy=TRUE)
```

## StoryMap
https://arcg.is/1fDKLD


## Motivation

 According to the CDC, suicide was the 10th leading cause of death in the US in 2015, and the 2nd leading cause of death among adolescents and young adults. Psychological disorders, particularly depression, are a significant risk factor for suicide especially when they go untreated. There is no reliable way to predict who is at risk for committing suicide, because most screening approaches depend on self-report information and people contemplating on suicide would often deny it when asked. 
 
 In the first part of our project, we hence aim to build a logistic regression model to identify important variables in predicting suicide rates. Due to the limits of our data, we consider the period from 2004-2015, within the scope of cities in California. One interesting explanatory variable we use is Google search term data (under the product of "Google Trends"). Our hypothesis is that individuals are more likely to tell the truth to Google, than on a questionnaire. In the second part of our project, we build a series of maps using the ArcGIS software. Using suicide rate and mental health treatment facilities data as well as Google search term data, our project aims to map the demand for and supply of mental health treatment in California cities.
 
 Ultimately, we hope to shed some light on important explanatory variables correlated with suicide rates (with the regression model), and to help identify cities where there is a large treatment service gap (with the maps) so that we can address this problem in a more data-driven way. 

- use result/visualization as hook

## Variable choice (to be moved to preceding corresponding R chunks)

 Ideally, the response variable that we are interested in is the gap between the demand and supply of mental health treatment. Which areas are over/under-served, and why? This would be very useful information to policy makers, mental health service providers, related non-profits and such. However, such a variable does not exist (or we could not find it), and we would have had to create an algorithm to derive this data from other existing variables. We could not decide on an accurate way to code "demand" (and what weights to give each component). Furthermore, even though "supply" is more straightforward, there also exists discrepancies between the size of the facilities, or the affordability of the services that would need to be captured by our variable. In the end, we decided that we would use suicide rate as a response variable, although we agreed that it would be an interesting extension to look at service gap. We also hope that our GIS maps would help our audience to begin to think about and identify areas which are under-served.
 
 The original datasets we start with include: 
 - List of verified mental health treatment clinics and facilities (downloaded from ReferenceUSA). We only included places with a certified psychiatrist or psychologist, and which focuses on general mental health (excluding substance abuse facilities)
 - Google search frequency by city on "depression" as a mood (to exclude unrelated searches on economic depression etc) from 2004-2015 (downloaded from Google Trends). The "hits" values are calculated on a scale from 0 to 100, where 100 is the location with the most popularity as a fraction of total searches, where 50 indicates a location which is half as popular and so on. 
 - Number of suicides by zipcode from 2004-2015. We downloaded leading causes of death data from California Health and Human Services Agency and filtered for cause of death is suicide.
 - Demographic data downloaded from SimplyAnalytics, including racial and gender makeup, age, marriage, education level, employment, income, healthcare, etc.
 - Cities long lat data (if possible, could we find a dataset which has a more exhaustive list, or I could ask Warren..)

## Playground

We originally intended to look at suicide rate and Google Trends data from one year, eg. 2015, but the logit model returned no significant variables as both suicide rate and depression search fluctuate a lot each year, influenced by factors like celebrity suicides which are not directly relevant to population mental health. Hence, we decided to aggregate suicide rate and Google Trends data over 12 years (constrained by data availability), from 2004 to 2015. Since demographic information is fairly stable over time, we used demographic information from the most recent year to train our model. 

```{r}
require(gtrendsR)
require(ggplot2)
require(dplyr)
require(zipcode)
data("zipcode")
require(ggmap)
```

## Making Dataframes

Longitude and latitude of cities (for mapping them later)
```{r}
cities_longlat<-read.csv("cal_cities.csv",header=TRUE) %>% select(c(location,Latitude,Longitude))
```

Full gtrends data for all cities for depression search
```{r}
gtrends_full <- read.csv("gtrends_20042015_full.csv") %>%
  `colnames<-`(c("location", "hits"))
```


Prepping facilities data to find number of facilities per city
```{r}
facilities<-read.csv("facilities_final.csv",header = TRUE)
colnames(facilities)[7]<-"zip"
facilities$zip<-as.character(facilities$zip)
city_facs<-facilities %>% group_by(City) %>% summarise(facility_cnt=n())
colnames(city_facs)[1]<-"location"
```

Prepping suicide data to find number of suicides per city, 2004-2015
```{r}
suis<-read.csv(file="death.csv",header=TRUE) %>% filter(Causes.of.Death=="SUI") %>% filter(Year >= 2004)
colnames(suis)[2]<-"zip"
suis$zip<-as.character(suis$zip)
suis2 <-inner_join(zipcode,suis,by="zip") 
# aggregate suicide data across all the years for each city
city_suis<-suis2 %>% group_by(city) %>% summarise(suicides=sum(Count))
colnames(city_suis)[1]<-"location"

# wrangled the data for the purpose of GIS (to use later)
zip_suis <- suis %>% group_by(zip) %>% summarise(suicides=sum(Count)) 

```

Adding in city demographic data for 2017
```{r}
citydem<-read.csv("citydems.csv",header=TRUE)
citydem2<-read.csv("citydems2.csv",header=TRUE)
citydem2$Name<-gsub(",.*","",citydem2$Name)
citydem$Name<-gsub(",.*","",citydem$Name)
citydem$FIPS<-NULL
citydem2$FIPS<-NULL
colnames(citydem)<-c("location", "male", "female","healthcare.per.household","bluecollar","whitecollar","nonfamily","medAge","NativeAm", "whiteNonHisp","hispanic","white","black","asian","medIncome","lessHS","HS","Bachelors","pop","unmarriedMpop","unemployed")
citydem<-inner_join(citydem,city_facs,by="location")
# Remove the Burbank and Mountain View entries that refer to census-designated areas (duplicate names with the actual cities will create problems later if not removed)
citydem <- citydem [-c(124,38), ]
citydem2 <- citydem2 [-c(636,803), ]
citydem$facility_cnt<-citydem$facility_cnt*100000/citydem$pop
colnames(citydem2)<-c("location","healthcare.per.person","activities.per.person","socialRec.per.person","entertainment.per.person","poverty","presdrugs.per.person","healthcarebiz.per.1000")

# data weangling for GIS mapping 
zipcode_dem <- read.csv("explansToViz-zipcode.csv")
zipcode_dem$Name<-gsub(",.*","",zipcode_dem$Name)
zipcode_dem$FIPS<-NULL
colnames(zipcode_dem)[1]<-"zip"
zipcode_dem$zip<-as.character(zipcode_dem$zip)
zipcode_dem2 <- zipcode_dem %>% left_join(zip_suis,by="zip") %>% left_join(zipcode,by="zip") %>% filter(state=="CA")
write.csv(zipcode_dem2,"gis_zip_dem.csv")
# add city area (in square miles) info from GIS
landArea <- foreign::read.dbf("LandCity.dbf")
landArea <- landArea[,c(1,3)]
colnames(landArea) <- c("location", "landArea")
```


```{r}
logtable <- inner_join(citydem,gtrends_full,by="location") %>% inner_join(city_suis,by="location") %>% inner_join(citydem2,by="location") %>% inner_join(landArea, by="location") %>% mutate(suicides=suicides*100000/pop,healthcare.per.person=healthcare.per.person/pop,activities.per.person=activities.per.person/pop,socialRec.per.person=socialRec.per.person/pop,entertainment.per.person=entertainment.per.person/pop,presdrugs.per.person=presdrugs.per.person/pop,healthcarebiz.per.1000=healthcarebiz.per.1000*1000/pop, pop_dens=landArea/pop)
```

If we want to reliably determine significant variables, we want to ensure that variables aren't collinear. Looking at the correlation plot of variables in logtable, we see significant correlation between some variables.

```{r fig1, fig.height = 8, fig.width = 8, fig.align = "center"}
library(corrplot)
corrplot(cor(logtable[,-1]))
```

To determine which variables to remove, we look at the VIF and choose variables with the highest VIFs to discount in the final analysis. We use a linear model using all variables to look at the initial VIF, and then remove variables one at a time, testing to see how the predictions and VIFs of our model change.

```{r}
library(DAAG)
set.seed(35)
model_full<-lm((suicides)~.,data=logtable[,-1])
test<-predict(model_full,logtable[,-1])
toCompare<-data.frame(cbind(actuals=logtable_crop.test$suicides,predicts=tests))
cor(toCompare)
vif(model_full)
```

We decide to remove activity, entertainment, social recreation, and healthcare spending per person, female, white(non-Hispanic), and white population, nonfamily households, and healthcare spending per household from the explanatory variables.
```{r}
logtable<-logtable %>% select(-c(activities.per.person,entertainment.per.person,female,whiteNonHisp,healthcare.per.person,socialRec.per.person,white,nonfamily,healthcare.per.household,asian,Bachelors,medIncome,black,HS,bluecollar,whitecollar))
# now the table has 174 cities, whereas the full list of gtrends had 200. Not a big loss
write.csv(logtable,"logtable.csv")

logtable_crop <- logtable [,-c(1)]
row.names(logtable_crop)<-logtable$location
# normalize the explanatory variables data frame
logtable_crop_normalized <- scale(logtable_crop) %>% data.frame()
row.names(logtable_crop_normalized)<-logtable$location


# for purpose of identifying which cities to map 
zip.no <- zipcode_dem2 %>% group_by(city) %>% summarise(zip.n=n())
colnames(zip.no)[1]<-"location"
#gistable <- logtable %>% select(c(1,19,24)) %>% left_join(zip.no,by="location")
# We wanted to choose one city with high suicide rate, and one with a low suicide rate. The two cities should have a similar population, and should have a min of 4 zipcodes (so that plotting variables at the zipcode level will be more useful). We eventually decided on Inglewood and Santa Barbara.  

```

We partition the data into a training and test set, then build our model.
```{r}
library(caret)
trains<-createDataPartition(logtable_crop$suicides,p=0.75,list=FALSE)
logtable_crop.train<-logtable_crop[trains,]
logtable_crop.test<-logtable_crop[-trains,]
set.seed(35)
model_full<-lm((suicides)~.,data=logtable_crop.train)
summary(model_full)

```

Significant variables include:
Facility density (#mental health facilities/100,000 people) (+), % population Native American(+), unemployment rate (-), % population Hispanic (-), and population density (+).  Borderline significant variables are median age (+) and % population in poverty (+).

We test our model on the test data and get a 83.1% correlation rate.

```{r}
tests<-predict(model_full,logtable_crop.test)
toCompare<-data.frame(cbind(actuals=logtable_crop.test$suicides,predicts=tests))
cor(toCompare)
head(toCompare)

```

Looking at the VIFs for the explanatory variables, we can see that 
```{r}
vif(model_full)
corrplot(cor(logtable_crop))
```


```{r}
require(ggrepel)
set.seed(35)
part<-sample(rownames(logtable_crop[logtable_crop$suicides>0,]),60)
locs.toUse<-logtable_crop[part,]
ggplot(locs.toUse,aes(x=NativeAm,y=log(suicides)))+geom_point(aes(color=facility_cnt>.4))+
  geom_label_repel(aes(fill=facility_cnt>quantile(logtable_crop$facility_cnt,0.5),label=part),fontface = 'bold',     color = 'black', box.padding = 0.5, point.padding = 1, segment.color = 'grey50')+
  theme_classic(base_size = 16)+
  theme(legend.position = "none", plot.title = element_text(size=15,hjust = 0.5), axis.text.x = element_text(size=5),
        axis.text.y = element_text(size=5), )+
  labs(title = "Suicides, Social Rec $, & Facility Density", y = "Log (suicide rates)", x = "Social Rec Spending")
```

```{r}
# clustering_table<-logtable_full_crop_normalized %>% select(presdrugs,socialRec,healthcarepp,facility_cnt,asian,AmInd)
# rownames(clustering_table)<-logtable_full[,1]
# dist_whole<-dist(clustering_table)
# cluster_whole<-hclust(dist_whole,method="centroid")
# plot(cluster_whole, labels=logtable_full[,1])
# groups=cutree(cluster_whole,k=20)
# groups
# x<-cbind(clustering_table, groups)
# 
# suis_cluster<-function(clus) {
#   sd<-logtable_full %>% filter(location %in% (rownames(subset(x,groups==clus)))) %>% .[["suicides"]] %>% log() %>% sd()
#   mean<-logtable_full %>% filter(location %in% (rownames(subset(x,groups==clus)))) %>% .[["suicides"]] %>% log() %>% mean()
#   #View(logtable_full%>% filter(location %in% (rownames(subset(x,groups==clus)))))
#   return(c(mean,sd))
# }
#  suis_cluster(5)
# #(lapply(1:12,suis_cluster))

```

```{r}
# set.seed(10)
# kcluster<-kmeans(clustering_table,20, nstart=20)$cluster
# kcluster
# y<-cbind(clustering_table,kcluster)
# logtable_full %>% filter(location %in% (rownames(subset(y,groups==17))))
```



}}
